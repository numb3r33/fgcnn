{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todos\n",
    "\n",
    "- [ ] Decompose this notebook into multiple notebooks \n",
    "    - [ ] one for data preparation ( training, validation and test )\n",
    "    - [ ] one for fgcnn\n",
    "    - [ ] one for ipnn\n",
    "    - [ ] one for experimenting with training dl models heuristics, e.g. observer batch loss graph etc.\n",
    "- [ ] Add docs about the paper and what are the key ideas.\n",
    "- [ ] Highlight input parameter calculation in the model notebooks.\n",
    "- [ ] Add section for the dataset used for validating model results.\n",
    "- [ ] Section for further ideas and current implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module name here\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from   pathlib import Path\n",
    "from   fastai.tabular.all import *\n",
    "import pandas as pd\n",
    "from   datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('/home/jovyan/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9460121, 24), test shape: (3870752, 24)\n",
      "CPU times: user 39.4 s, sys: 2.12 s, total: 41.5 s\n",
      "Wall time: 41.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "date_parser = lambda date: datetime.strptime(date, '%y%m%d%H')\n",
    "\n",
    "df      = pd.read_csv(DATA_DIR / 'train', nrows=14000000, #parse_dates=['hour'], date_parser=date_parser\n",
    "                     )\n",
    "# test set is any row on `141023`\n",
    "df_test = df.loc[df.hour.astype('str').str.slice(0, 6) == '141023']\n",
    "\n",
    "# train set is any row \n",
    "df      = df.loc[df.hour < 14102300]\n",
    "\n",
    "print(f'train shape: {df.shape}, test shape: {df_test.shape}')\n",
    "\n",
    "#df_test = pd.read_csv(DATA_DIR / 'test' , parse_dates=['hour'], date_parser=date_parser)\n",
    "\n",
    "# decompose hour into weekday and hour\n",
    "# df = df.assign(weekday=df.hour.dt.weekday)\n",
    "# df = df.assign(click_hour=df.hour.dt.hour)\n",
    "\n",
    "# df_test = df_test.assign(weekday=df_test.hour.dt.weekday)\n",
    "# df_test = df_test.assign(click_hour=df_test.hour.dt.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decompose hour into weekday and hour\n",
    "df      = df.assign(click_hour=df.hour.astype('str').str.slice(6))\n",
    "df_test = df_test.assign(click_hour=df_test.hour.astype('str').str.slice(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HourSplitter(hour='141022', seed=None):\n",
    "    \"Create function that splits `items` between train/val with based on date.\"\n",
    "    def _inner(o):\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        indices  = o.index.values\n",
    "        valid    = np.where(o.hour.astype(str).str.slice(0, 6) == hour)[0]\n",
    "        train    = list(set(indices) - set(valid))\n",
    "        \n",
    "        return indices[train],indices[valid]\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.83541\n",
       "1    0.16459\n",
       "Name: click, dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.click.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.6 s, sys: 3.12 s, total: 43.8 s\n",
      "Wall time: 43.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cat_names  = ['C1', 'banner_pos', 'site_id', 'site_domain',\n",
    "              'site_category', 'app_id', 'app_domain', 'app_category',\n",
    "              'device_id', 'device_ip', 'device_model', 'device_type',\n",
    "              'click_hour', 'device_conn_type', 'C14', 'C15',\n",
    "              'C16', 'C17', 'C18', 'C19', 'C20', 'C21'\n",
    "             ]\n",
    "\n",
    "cont_names = []\n",
    "procs      = [Categorify, FillMissing]\n",
    "\n",
    "splits = HourSplitter(seed=41)(df)\n",
    "# splits = RandomSplitter(seed=41)(df)\n",
    "dls    = TabularDataLoaders.from_df(df, \n",
    "                                 path='.', \n",
    "                                 procs=procs, \n",
    "                                 cat_names=cat_names, \n",
    "                                 cont_names=cont_names, \n",
    "                                 y_names=\"click\", \n",
    "                                 splits=splits, \n",
    "                                 bs=2048\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_domain</th>\n",
       "      <th>app_category</th>\n",
       "      <th>device_id</th>\n",
       "      <th>device_ip</th>\n",
       "      <th>device_model</th>\n",
       "      <th>device_type</th>\n",
       "      <th>click_hour</th>\n",
       "      <th>device_conn_type</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8197153</th>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>e151e245</td>\n",
       "      <td>7e091613</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>332dc66b</td>\n",
       "      <td>76dc4769</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>21882</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2526</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815298</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>e2fcccd2</td>\n",
       "      <td>5c5a694b</td>\n",
       "      <td>0f2161f8</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>23cfd878</td>\n",
       "      <td>a8964a12</td>\n",
       "      <td>1</td>\n",
       "      <td>08</td>\n",
       "      <td>0</td>\n",
       "      <td>6560</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>571</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>100048</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6789492</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>e9739828</td>\n",
       "      <td>df32afa9</td>\n",
       "      <td>cef3e649</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>3e2c01db</td>\n",
       "      <td>e47f989b</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>21767</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2506</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100020</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063646</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>66f5e02e</td>\n",
       "      <td>6f7ca2ba</td>\n",
       "      <td>0f2161f8</td>\n",
       "      <td>c28f0035</td>\n",
       "      <td>c5d4327c</td>\n",
       "      <td>9e3836ff</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>21772</td>\n",
       "      <td>300</td>\n",
       "      <td>50</td>\n",
       "      <td>2507</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809392</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>d9750ee7</td>\n",
       "      <td>98572c79</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>d01c28e4</td>\n",
       "      <td>4ceb2e0b</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>17914</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2043</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>100084</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8312094</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>1812cdb7</td>\n",
       "      <td>23885c9e</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>15704</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3817921</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>8bbb7062</td>\n",
       "      <td>ef1fc174</td>\n",
       "      <td>0f2161f8</td>\n",
       "      <td>5c01cfbc</td>\n",
       "      <td>2b0f4c31</td>\n",
       "      <td>fce66524</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>21189</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2424</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>-1</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4375335</th>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>5b4d2eda</td>\n",
       "      <td>16a36ef3</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>0cdc2afe</td>\n",
       "      <td>76dc4769</td>\n",
       "      <td>1</td>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>19950</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1800</td>\n",
       "      <td>3</td>\n",
       "      <td>167</td>\n",
       "      <td>100075</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324163</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>e2a1ca37</td>\n",
       "      <td>2347f47a</td>\n",
       "      <td>8ded1f7a</td>\n",
       "      <td>ee459291</td>\n",
       "      <td>ad01d971</td>\n",
       "      <td>47a322d1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>17016</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1873</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8414628</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>7358e05e</td>\n",
       "      <td>b9528b13</td>\n",
       "      <td>cef3e649</td>\n",
       "      <td>7961236b</td>\n",
       "      <td>a1ce9c97</td>\n",
       "      <td>684581ce</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1037</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>178</td>\n",
       "      <td>3</td>\n",
       "      <td>1327</td>\n",
       "      <td>-1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fixed_emb_sz(classes, n, k):\n",
    "    \"Pick a fixed embedding size for `n` based on `k`.\"\n",
    "    n_cat = len(classes[n])\n",
    "    sz    = k  # rule of thumb\n",
    "    return n_cat,sz\n",
    "\n",
    "def get_emb_sz(to, k):\n",
    "    \"Get default embedding size from `TabularPreprocessor` `proc` or the ones in `sz_dict`\"\n",
    "    return [_fixed_emb_sz(to.classes, n, k) for n in to.cat_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avazu Model ( FGCNN v2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvPoolRecombine(Module):\n",
    "    \"\"\"\n",
    "    input : ( N, C_in, H, W ), where w represents `k` ( emebdding size )\n",
    "    output: ( N, new_i, H / 2, W), where `2` represents max pool kernel size which is fixed as `2` for now.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ch_in, ch_out, recomb_ch_out, out_wh, h, hp):\n",
    "        store_attr()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=ch_in,\n",
    "                              out_channels=ch_out,\n",
    "                              kernel_size=(h, 1),\n",
    "                              padding='same',\n",
    "                              stride=(1, 1)\n",
    "                             )\n",
    "        \n",
    "        self.tanh   = nn.Tanh()\n",
    "        self.pool   = nn.MaxPool2d(kernel_size=(hp, 1))\n",
    "        \n",
    "        self.recomb = nn.Linear(out_wh*ch_out, out_wh*recomb_ch_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        embed_size = x.shape[3]\n",
    "        \n",
    "        # output shape: (N, C_out, H, W)\n",
    "        c = self.conv(x)\n",
    "        c = self.tanh(c)\n",
    "        \n",
    "        # output shape: (N, C_out, H / hp, W), where hp = `2`\n",
    "        p = self.pool(c)\n",
    "        \n",
    "        # output shape: (N, H / hp, W, C_out)\n",
    "        f = p.permute([0, 2, 3, 1]).contiguous()\n",
    "        \n",
    "        # flattening\n",
    "        # shape: (N, H/2*W*C_out)\n",
    "        f = f.view(batch_size, -1)\n",
    "        \n",
    "        # recombining\n",
    "        # shape: (N, H/2, W, C_new)\n",
    "        r = self.recomb(f).view(batch_size, -1, embed_size, self.recomb_ch_out)\n",
    "        \n",
    "        # shape: (N, c_new*H/hp, W)\n",
    "        out_r = r.permute([0, 3, 1, 2]).contiguous().view(batch_size, -1, embed_size)\n",
    "        \n",
    "        return p, out_r\n",
    "    \n",
    "class FGCNN_v2(Module):\n",
    "    def __init__(self, emb_szs, conv_kernels, kernels, dense_layers, h, hp):\n",
    "        \"\"\"\n",
    "        emb_szs     : list of tuples representing embedding size e.g. [(4, k), (6, k)]\n",
    "        conv_kernels: list of convolutional kernels\n",
    "        kernels     : kernels to be used\n",
    "        h           : convolutional filter size\n",
    "        hp          : pooling kernel size\n",
    "        \"\"\"\n",
    "        \n",
    "        self.k        = emb_szs[0][1]\n",
    "        self.n_fields = len(emb_szs) \n",
    "        self.embeds   = nn.ModuleList([Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.n_emb    = sum(e.embedding_dim for e in self.embeds)\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList([ConvPoolRecombine(ch_in=1 if i == 0 else conv_kernels[i-1], \n",
    "                                                            ch_out=conv_kernels[i], \n",
    "                                                            recomb_ch_out=kernels[i],\n",
    "                                                            out_wh=int(self.n_fields / (2 ** (i + 1))) * self.k,\n",
    "                                                            h=h, \n",
    "                                                            hp=hp\n",
    "                                                           ) for i in range(len(conv_kernels))\n",
    "                                         ])\n",
    "        \n",
    "        N = np.sum([int(self.n_fields / (hp ** (i + 1))) for i in range(len(conv_kernels))]) * kernels[0]\n",
    "        \n",
    "        self.lin_in = self.n_fields * self.k + int((N + self.n_fields) * (N + self.n_fields - 1) / 2)\n",
    "        \n",
    "        # MLP classifier\n",
    "        self.act = nn.ReLU()\n",
    "        self.mlp = nn.ModuleList([LinBnDrop(n_in=self.lin_in if i == 0  else dense_layers[i-1], \n",
    "                                            n_out=dense_layers[i],\n",
    "                                            act=self.act\n",
    "                                            ) \n",
    "                                          for i in range(len(dense_layers))\n",
    "                                 ])\n",
    "         \n",
    "        self.final_linear = nn.Linear(in_features=dense_layers[-1], out_features=1, bias=False)\n",
    "        self.sigmoid      = nn.Sigmoid()\n",
    "        \n",
    "        store_attr()\n",
    "    \n",
    "    def forward(self, x, x_cont):\n",
    "        bs = x.shape[0]\n",
    "        \n",
    "        if self.n_emb != 0:\n",
    "            x = [e(x[:,i]).unsqueeze(dim=1) for i,e in enumerate(self.embeds)]\n",
    "            x = torch.cat(x, 1)\n",
    "            \n",
    "        embed = x.clone()\n",
    "        \n",
    "        input_x = x.view(bs, 1, self.n_fields, self.k)\n",
    "        \n",
    "        p     = input_x\n",
    "        out_r = []\n",
    "        for i in range(len(self.conv_layers)):\n",
    "            p, r = self.conv_layers[i](p)\n",
    "            out_r.append(r)\n",
    "        \n",
    "        # shape: (bs, C_new * ( H / 2 ^ i), embed_size)\n",
    "        new_features = torch.cat(out_r, dim=1)\n",
    "        \n",
    "        # combine features\n",
    "        aug_emb = torch.cat([embed, new_features], dim=1)\n",
    "        \n",
    "        # inner product factorization machine using augmented embedding matrix\n",
    "        fm = []\n",
    "        \n",
    "        for i in range(aug_emb.shape[1]):\n",
    "            for j in range(i+1, aug_emb.shape[1]):\n",
    "                fm.append(torch.sum(torch.mm(aug_emb[:,i,:],\n",
    "                                             aug_emb[:,j,:].T), dim=1\n",
    "                                   ).unsqueeze(dim=1))\n",
    "\n",
    "        fm  = torch.cat(fm, dim=1)\n",
    "        \n",
    "        # flatten\n",
    "        out = torch.cat([fm, embed.view(bs, -1)], dim=1)\n",
    "        \n",
    "        for i in range(len(self.mlp)):\n",
    "            out = self.mlp[i](out)\n",
    "            \n",
    "        out = self.final_linear(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avazu Model ( FGCNN v1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_conv(ni, mc, h, hp):\n",
    "    return nn.Sequential(nn.Conv2d(in_channels=ni, \n",
    "                                   out_channels=mc, \n",
    "                                   kernel_size=(h, 1), \n",
    "                                   padding='same', \n",
    "                                   stride=(1, 1)\n",
    "                                  ),\n",
    "                         nn.Tanh(),\n",
    "                         nn.MaxPool2d(kernel_size=(hp, 1))\n",
    "                        )\n",
    "\n",
    "def _make_recombination(nf, hp, k, mc, mr):\n",
    "    fan_in = (nf // hp ) if (nf // hp) > 0 else 1\n",
    "    return nn.Linear(in_features=fan_in*k*mc,\n",
    "                     out_features=fan_in*k*mr\n",
    "                    )\n",
    "\n",
    "\n",
    "class IPNN(Module):\n",
    "    def __init__(self, dense_layers):\n",
    "        self.flatten     = nn.Flatten()\n",
    "        self.act         = nn.ReLU()\n",
    "        \n",
    "        self.lin_bn_drop = nn.ModuleList([LinBnDrop(n_in=dense_layers[i], \n",
    "                                                    n_out=dense_layers[i+1],\n",
    "                                                    act=self.act\n",
    "                                                   ) \n",
    "                                          for i in range(len(dense_layers) - 1)\n",
    "                                         ])\n",
    "        \n",
    "        self.final_linear = nn.Linear(in_features=dense_layers[-1], out_features=1, bias=False)\n",
    "        self.sigmoid      = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, aug_emb):\n",
    "        fm = []\n",
    "        \n",
    "        for i in range(aug_emb.shape[1]):\n",
    "            for j in range(i+1, aug_emb.shape[1]):\n",
    "                fm.append(torch.sum(torch.mm(aug_emb[:,i,:],\n",
    "                                             aug_emb[:,j,:].T), dim=1\n",
    "                                   ).unsqueeze(dim=1))\n",
    "\n",
    "        fm  = torch.cat(fm, dim=1)\n",
    "        rfm = torch.cat((fm, self.flatten(aug_emb)), dim=1)\n",
    "        \n",
    "        dense_out = rfm\n",
    "        for i in range(len(self.lin_bn_drop)):\n",
    "            dense_out = self.lin_bn_drop[i](dense_out)\n",
    "        \n",
    "        final_res = self.final_linear(dense_out)\n",
    "        out       = self.sigmoid(final_res)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "class FGCNN(Module):\n",
    "    def __init__(self, emb_szs, conv_kernels, kernels, h, hp):\n",
    "        \"\"\"\n",
    "        emb_szs     : list of tuples representing embedding size e.g. [(4, k), (6, k)]\n",
    "        conv_kernels: list of convolutional kernels\n",
    "        kernels     : kernels to be used\n",
    "        h           : convolutional filter size\n",
    "        hp          : pooling kernel size\n",
    "        \"\"\"\n",
    "        \n",
    "        self.k      = emb_szs[0][1]\n",
    "        self.embeds = nn.ModuleList([Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.n_emb  = sum(e.embedding_dim for e in self.embeds)\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList([_make_conv(ni=1, mc=conv_kernels[0], h=h, hp=hp)]  +\\\n",
    "                                         [_make_conv(conv_kernels[i-1], conv_kernels[i], h=h, hp=hp) \\\n",
    "                                         for i in range(1, len(conv_kernels))]\n",
    "                                        )\n",
    "        \n",
    "        nf          = len(self.embeds)\n",
    "        self.linear = nn.ModuleList()\n",
    "        \n",
    "        for i in range(len(conv_kernels)):\n",
    "            self.linear.append(_make_recombination(nf // (hp ** i), hp, self.k, conv_kernels[i], mr=kernels[i]))\n",
    "            \n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "            \n",
    "        store_attr()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        \n",
    "        if self.n_emb != 0:\n",
    "            x = [e(x[:,i]).unsqueeze(dim=1) for i,e in enumerate(self.embeds)]\n",
    "            x = torch.cat(x, 1)\n",
    "        \n",
    "        # embed is embedding matrix that would be used in deep\n",
    "        # classifier.\n",
    "        embed = x.clone()\n",
    "        \n",
    "        # x is embedding matrix used for feature generation\n",
    "        x   = x.unsqueeze(dim=1) # adding a single channel for convolution\n",
    "        out = x\n",
    "        recombined = []\n",
    "        \n",
    "        for i in range(len(self.conv_layers)):\n",
    "            out = self.conv_layers[i](out)\n",
    "            \n",
    "            flat = self.flatten(out)\n",
    "            flat = self.linear[i](flat)\n",
    "            flat = flat.reshape(bs, -1, self.k)\n",
    "            \n",
    "            recombined.append(flat)\n",
    "            \n",
    "        recombined = torch.cat(recombined, dim=1)\n",
    "        recombined = torch.cat((recombined, embed), dim=1)\n",
    "\n",
    "        return recombined        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvazuModel(Module):\n",
    "    def __init__(self, k, emb_szs, conv_kernels=[6, 8], kernels=[3, 3], h=7, hp=2, dense_layers=[]):\n",
    "        # store all attributes\n",
    "        store_attr()\n",
    "        \n",
    "        self.fgcnn   = FGCNN(emb_szs, conv_kernels, kernels, h, hp)\n",
    "        self.n_fgcnn = self.get_num_feats(emb_szs, kernels)\n",
    "        \n",
    "        tot_f = len(emb_szs) + self.n_fgcnn\n",
    "        tot_f = (tot_f * k) + (((tot_f * (tot_f - 1)) / 2))\n",
    "        \n",
    "        dense_layers = [int(tot_f)] + dense_layers\n",
    "        self.ipnn    = IPNN(dense_layers)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        out = self.fgcnn(x_cat)\n",
    "        out = self.ipnn(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def get_num_feats(self, emb_szs, kernels):\n",
    "        n_feats  = len(emb_szs)\n",
    "        num_maps = n_feats \n",
    "        n = 0\n",
    "        for i in range(len(kernels)):\n",
    "            n += kernels[i] * (n_feats // (self.hp ** (i + 1)))\n",
    "            \n",
    "        return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats, conts, y = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 1])\n"
     ]
    }
   ],
   "source": [
    "emb_szs = get_emb_sz(dls.train_ds, k=40)\n",
    "\n",
    "m = FGCNN_v2(emb_szs=emb_szs, \n",
    "             conv_kernels=[6, 8, 10, 12], \n",
    "             kernels=[2, 2, 2, 2],\n",
    "             dense_layers=[256, 128, 64],\n",
    "             h=7,\n",
    "             hp=2\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avazu Model using FGCNN v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs = get_emb_sz(dls.train_ds, k=40)\n",
    "m       = AvazuModel(k=40, \n",
    "                     emb_szs=emb_szs, \n",
    "                     conv_kernels=[14, 16, 18, 20], \n",
    "                     kernels=[3, 3, 3, 3],\n",
    "                     dense_layers=[256, 128, 64]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGCNN v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs = get_emb_sz(dls.train_ds, k=40)\n",
    "\n",
    "m = FGCNN_v2(emb_szs=emb_szs, \n",
    "             conv_kernels=[14, 16, 18, 20], \n",
    "             kernels=[3, 3, 3, 3],\n",
    "             dense_layers=[4096, 2048, 1024, 512],\n",
    "             h=7,\n",
    "             hp=2\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = TabularLearner(dls, m, loss_func=BCELossFlat(), opt_func=ranger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/my-conda-envs/dev/lib/python3.8/site-packages/fastai/callback/schedule.py:269: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"ro\" (-> color='r'). The keyword argument will take precedence.\n",
      "  ax.plot(val, idx, 'ro', label=nm, c=color)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=0.00019054606673307717)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2093' class='' max='3695' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      56.64% [2093/3695 4:04:50<3:07:23 0.3422]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_flat_cos(1, 2e-4, cbs=EarlyStoppingCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "learn.save(file=DATA_DIR / 'models' / 'fgcnn_v2_single_epoch_es_but_last_day.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dl    = learn.dls.test_dl(df_test)\n",
    "preds = learn.get_preds(dl=dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBase(0.4240)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = BCELossFlat()\n",
    "tst(preds[0], torch.tensor(df_test['click'].values).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(DATA_DIR / 'sampleSubmission')\n",
    "sub.loc[:, 'click'] = preds[0].squeeze(dim=1).cpu().numpy()\n",
    "\n",
    "sub.to_csv(DATA_DIR / 'submissions' / 'fgcnn_v2_single_epoch_es_but_last_day.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
