{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08693ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387fc648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.tabular.all import *\n",
    "from fgcnn.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52646c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ced7bd7",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "\n",
    "> Module to prepare data for experiments\n",
    "\n",
    "The methods provide way to create train and test datasets, splitter and dataloaders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af447bd6",
   "metadata": {},
   "source": [
    "### Prepare dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c5ec2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_domain</th>\n",
       "      <th>app_category</th>\n",
       "      <th>device_id</th>\n",
       "      <th>device_ip</th>\n",
       "      <th>device_model</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_conn_type</th>\n",
       "      <th>click_hour</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3280536</th>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>826c565e</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>0f2161f8</td>\n",
       "      <td>8a7fb045</td>\n",
       "      <td>be23dbfa</td>\n",
       "      <td>f07e20f8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>21790</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2513</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013407</th>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "      <td>1ee69d19</td>\n",
       "      <td>ce81106c</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>60b5cd1b</td>\n",
       "      <td>e2c233db</td>\n",
       "      <td>507de649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>04</td>\n",
       "      <td>15908</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1752</td>\n",
       "      <td>3</td>\n",
       "      <td>297</td>\n",
       "      <td>100081</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7790564</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>36f58dec</td>\n",
       "      <td>2347f47a</td>\n",
       "      <td>f95efa07</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>8e787681</td>\n",
       "      <td>d780319b</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>21767</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2506</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6718210</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>e9739828</td>\n",
       "      <td>df32afa9</td>\n",
       "      <td>cef3e649</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>d6c0acb1</td>\n",
       "      <td>e55b4de4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>21768</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2506</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100020</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4512824</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>66f5e02e</td>\n",
       "      <td>6f7ca2ba</td>\n",
       "      <td>0f2161f8</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>fc895806</td>\n",
       "      <td>2891f384</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>03</td>\n",
       "      <td>21678</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2495</td>\n",
       "      <td>2</td>\n",
       "      <td>167</td>\n",
       "      <td>-1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6886687</th>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>a37bf1e4</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>dce843f8</td>\n",
       "      <td>97d296f6</td>\n",
       "      <td>3bcda2fe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>14265</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1526</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>100111</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909109</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>cd58172f</td>\n",
       "      <td>b9c4ab81</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>cfcbdff7</td>\n",
       "      <td>158e4944</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>17877</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2036</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648145</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>23d99ea0</td>\n",
       "      <td>6bdbd889</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>339649fc</td>\n",
       "      <td>6e1e2240</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>03</td>\n",
       "      <td>16208</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1800</td>\n",
       "      <td>3</td>\n",
       "      <td>167</td>\n",
       "      <td>100074</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5713179</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>4e7614cf</td>\n",
       "      <td>c1aa3c04</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>07d7df22</td>\n",
       "      <td>a99f214a</td>\n",
       "      <td>e70f5b2e</td>\n",
       "      <td>8ef046ab</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>08</td>\n",
       "      <td>21764</td>\n",
       "      <td>216</td>\n",
       "      <td>36</td>\n",
       "      <td>2506</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100076</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3903661</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>7358e05e</td>\n",
       "      <td>b9528b13</td>\n",
       "      <td>cef3e649</td>\n",
       "      <td>8c2d936a</td>\n",
       "      <td>4b44384d</td>\n",
       "      <td>be6db1d7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>456</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>1319</td>\n",
       "      <td>-1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "dls = get_dl()\n",
    "dls.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78951509",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68283eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _fixed_emb_sz(classes, n, k):\n",
    "    \"Pick a fixed embedding size for `n` based on `k`.\"\n",
    "    n_cat = len(classes[n])\n",
    "    sz    = k  # rule of thumb\n",
    "    return n_cat,sz\n",
    "\n",
    "def get_emb_sz(to, k):\n",
    "    \"Get default embedding size from `TabularPreprocessor` `proc` or the ones in `sz_dict`\"\n",
    "    return [_fixed_emb_sz(to.classes, n, k) for n in to.cat_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e884b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 40),\n",
       " (8, 40),\n",
       " (3513, 40),\n",
       " (4608, 40),\n",
       " (24, 40),\n",
       " (5501, 40),\n",
       " (392, 40),\n",
       " (34, 40),\n",
       " (787082, 40),\n",
       " (2157569, 40),\n",
       " (6885, 40),\n",
       " (5, 40),\n",
       " (5, 40),\n",
       " (25, 40),\n",
       " (1089, 40),\n",
       " (9, 40),\n",
       " (10, 40),\n",
       " (239, 40),\n",
       " (5, 40),\n",
       " (51, 40),\n",
       " (169, 40),\n",
       " (44, 40)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#slow\n",
    "get_emb_sz(dls, k=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04a5455",
   "metadata": {},
   "source": [
    "## FGCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7425b08",
   "metadata": {},
   "source": [
    "Convolution -> Max Pooling -> Recombination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f6994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ConvPoolRecombine(Module):\n",
    "    \"\"\"\n",
    "    input : ( N, C_in, H, W ), where w represents `k` ( emebdding size )\n",
    "    output: ( N, new_i, H / 2, W), where `2` represents max pool kernel size which is fixed as `2` for now.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ch_in, ch_out, recomb_ch_out, out_wh, h, hp):\n",
    "        store_attr()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=ch_in,\n",
    "                              out_channels=ch_out,\n",
    "                              kernel_size=(h, 1),\n",
    "                              padding='same',\n",
    "                              stride=(1, 1)\n",
    "                             )\n",
    "        \n",
    "        self.tanh   = nn.Tanh()\n",
    "        self.pool   = nn.MaxPool2d(kernel_size=(hp, 1))\n",
    "        \n",
    "        self.recomb = nn.Linear(out_wh*ch_out, out_wh*recomb_ch_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        embed_size = x.shape[3]\n",
    "        \n",
    "        # output shape: (N, C_out, H, W)\n",
    "        c = self.conv(x)\n",
    "        c = self.tanh(c)\n",
    "        \n",
    "        # output shape: (N, C_out, H / hp, W), where hp = `2`\n",
    "        p = self.pool(c)\n",
    "        \n",
    "        # output shape: (N, H / hp, W, C_out)\n",
    "        f = p.permute([0, 2, 3, 1]).contiguous()\n",
    "        \n",
    "        # flattening\n",
    "        # shape: (N, H/2*W*C_out)\n",
    "        f = f.view(batch_size, -1)\n",
    "        \n",
    "        # recombining\n",
    "        # shape: (N, H/2, W, C_new)\n",
    "        r = self.recomb(f).view(batch_size, -1, embed_size, self.recomb_ch_out)\n",
    "        \n",
    "        # shape: (N, c_new*H/hp, W)\n",
    "        out_r = r.permute([0, 3, 1, 2]).contiguous().view(batch_size, -1, embed_size)\n",
    "        \n",
    "        return p, out_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FGCNN(Module):\n",
    "    def __init__(self, emb_szs, conv_kernels, kernels, dense_layers, h, hp):\n",
    "        \"\"\"\n",
    "        emb_szs     : list of tuples representing embedding size e.g. [(4, k), (6, k)]\n",
    "        conv_kernels: list of convolutional kernels\n",
    "        kernels     : kernels to be used\n",
    "        h           : convolutional filter size\n",
    "        hp          : pooling kernel size\n",
    "        \"\"\"\n",
    "        \n",
    "        self.k        = emb_szs[0][1]\n",
    "        self.n_fields = len(emb_szs) \n",
    "        self.embeds   = nn.ModuleList([Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.n_emb    = sum(e.embedding_dim for e in self.embeds)\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList([ConvPoolRecombine(ch_in=1 if i == 0 else conv_kernels[i-1], \n",
    "                                                            ch_out=conv_kernels[i], \n",
    "                                                            recomb_ch_out=kernels[i],\n",
    "                                                            out_wh=int(self.n_fields / (2 ** (i + 1))) * self.k,\n",
    "                                                            h=h, \n",
    "                                                            hp=hp\n",
    "                                                           ) for i in range(len(conv_kernels))\n",
    "                                         ])\n",
    "        \n",
    "        N = np.sum([int(self.n_fields / (hp ** (i + 1))) for i in range(len(conv_kernels))]) * kernels[0]\n",
    "        \n",
    "        self.lin_in = self.n_fields * self.k + int((N + self.n_fields) * (N + self.n_fields - 1) / 2)\n",
    "        \n",
    "        # MLP classifier\n",
    "        self.act = nn.ReLU()\n",
    "        self.mlp = nn.ModuleList([LinBnDrop(n_in=self.lin_in if i == 0  else dense_layers[i-1], \n",
    "                                            n_out=dense_layers[i],\n",
    "                                            act=self.act\n",
    "                                            ) \n",
    "                                          for i in range(len(dense_layers))\n",
    "                                 ])\n",
    "         \n",
    "        self.final_linear = nn.Linear(in_features=dense_layers[-1], out_features=1, bias=False)\n",
    "        self.sigmoid      = nn.Sigmoid()\n",
    "        \n",
    "        store_attr()\n",
    "    \n",
    "    def forward(self, x, x_cont):\n",
    "        bs = x.shape[0]\n",
    "        \n",
    "        if self.n_emb != 0:\n",
    "            x = [e(x[:,i]).unsqueeze(dim=1) for i,e in enumerate(self.embeds)]\n",
    "            x = torch.cat(x, 1)\n",
    "            \n",
    "        embed = x.clone()\n",
    "        \n",
    "        input_x = x.view(bs, 1, self.n_fields, self.k)\n",
    "        \n",
    "        p     = input_x\n",
    "        out_r = []\n",
    "        for i in range(len(self.conv_layers)):\n",
    "            p, r = self.conv_layers[i](p)\n",
    "            out_r.append(r)\n",
    "        \n",
    "        # shape: (bs, C_new * ( H / 2 ^ i), embed_size)\n",
    "        new_features = torch.cat(out_r, dim=1)\n",
    "        \n",
    "        # combine features\n",
    "        aug_emb = torch.cat([embed, new_features], dim=1)\n",
    "        \n",
    "        # inner product factorization machine using augmented embedding matrix\n",
    "        fm = []\n",
    "        \n",
    "        for i in range(aug_emb.shape[1]):\n",
    "            for j in range(i+1, aug_emb.shape[1]):\n",
    "                fm.append(torch.sum(torch.mm(aug_emb[:,i,:],\n",
    "                                             aug_emb[:,j,:].T), dim=1\n",
    "                                   ).unsqueeze(dim=1))\n",
    "\n",
    "        fm  = torch.cat(fm, dim=1)\n",
    "        \n",
    "        # flatten\n",
    "        out = torch.cat([fm, embed.view(bs, -1)], dim=1)\n",
    "        \n",
    "        for i in range(len(self.mlp)):\n",
    "            out = self.mlp[i](out)\n",
    "            \n",
    "        out = self.final_linear(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
