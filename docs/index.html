---

title: FGCNN 


keywords: fastai
sidebar: home_sidebar

summary: "Implementation of Feature Generation by Convolutional Neural Networks using `fast.ai`."
description: "Implementation of Feature Generation by Convolutional Neural Networks using `fast.ai`."
nb_path: "index.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Abstract taken from <a href="https://arxiv.org/abs/1904.04447">paper</a></p>
<blockquote><p>Click-Through Rate prediction is an important task in recommender systems, which aims to estimate the probability of a user to click on a given item. Recently, many deep models have been proposed to learn low-order and high-order feature interactions from original features. However, since useful interactions are always sparse, it is difficult for DNN to learn them effectively under a large number of parameters. In real scenarios, artificial features are able to improve the performance of deep models (such as Wide &amp; Deep Learning), but feature engineering is expensive and requires domain knowledge, making it impractical in different scenarios. Therefore, it is necessary to augment feature space automatically. In this paper, We propose a novel Feature Generation by Convolutional Neural Network (FGCNN) model with two components:Feature Generation and Deep Classifier. Feature Generation leverages the strength of CNN to generate local patterns and recombine them to generate new features. Deep Classifier adopts the structure of IPNN to learn interactions from the augmented feature space. Experimental results on three large-scale datasets show that FGCNN significantly outperforms nine state-of-the-art models. Moreover, when applying some state-of-the-art models as Deep Classifier, better performance is always achieved, showing the great compatibility of our FGCNN model. This work explores a novel direction for CTR predictions: it is quite useful to reduce the learning difficulties of DNN by automatically identifying important features.</p>
</blockquote>
<ul>
<li>Extracting effective and efficient features for this task is very expensive and requires domain expertise.</li>
<li>This work proposes to use FGCNN ( Feature Generation by CNN ) to solve this problem.</li>
<li>CNN is used to extract local patterns which are then combined to generate new features.</li>
</ul>
<p><img src="/fgcnn/./images/comparison.png" alt="Wide vs FGCNN"></p>
<ul>
<li><p>It is difficult for DNN to learn feature interactions because these are very sparse. e.g. suppose we want to calculate the probablity of a user downloading a game given features like <code>age</code>, <code>country</code>, <code>gender</code>, <code>city</code> and turns out that only <code>age</code> and <code>country</code> are useful in predicting the outcome variable and rest is noise. It becomes very hard for DNN to learn that embeddings for <code>country</code> and <code>city</code> must be <code>0</code>.</p>
</li>
<li><p>CNN alone cannot solve this problem because there is no transitional invariance among the features ( <code>age</code>, <code>gender</code>, <code>country</code>, <code>city</code> ) is similar to ( <code>age</code>, <code>gender</code>, <code>city</code>, <code>country</code> ), so that is why the author has proposed to use CNNs with MLPs as shown in the following figure</p>
</li>
</ul>
<p><img src="/fgcnn/./images/model_arch.png" alt="Model Architecture"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Input-dataset-requirements">Input dataset requirements<a class="anchor-link" href="#Input-dataset-requirements"> </a></h3><ul>
<li>For most of the ctr prediction tasks, data is collected in the form of <code>multi-field</code> categorical form such that each feature could be transformed into high dimensional sparse ( binary ) vector via one hot encoding as an example.</li>
<li>For example, (Gender=Male, Height=175, Age=18, Name=Bob) can be represented as:</li>
</ul>
<p><img src="/fgcnn/./images/multi_field.png" alt="multi_field"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Model-structure">Model structure<a class="anchor-link" href="#Model-structure"> </a></h3><ul>
<li>Feature Embedding Layer : Every categorical field is passed through an embedding layer before passing to feature generation module.</li>
<li>Feature Generation Layer: ( CNN + Recombination ) layer. CNN extracts useful neighbor patterns and recombination layer generates global feature interactions.</li>
<li>Deep Classifier Layer: IPNN model shown below</li>
</ul>
<p><img src="/fgcnn/./images/ipnn_model.png" alt=""></p>
<p><strong>We could use any custom model ( FM, DNN, IPNN, DeepFM etc. ) in the deep classifier layer based on the task at hand.</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Loss-Function">Loss Function<a class="anchor-link" href="#Loss-Function"> </a></h3><p><img src="/fgcnn/./images/loss_func.png" alt="loss_func"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Experiments">Experiments<a class="anchor-link" href="#Experiments"> </a></h3><p><img src="/fgcnn/./images/experiments.png" alt="experiments"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>We have tried to use the <a href="">Avazu</a> dataset for our experiments.</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Install">Install<a class="anchor-link" href="#Install"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>pip install git+https://github.com/numb3r33/fgcnn.git</code></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-to-use">How to use<a class="anchor-link" href="#How-to-use"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># prepare data loaders</span>
<span class="n">dls</span>     <span class="o">=</span> <span class="n">get_dl</span><span class="p">()</span>

<span class="c1"># prepare embedding matrix</span>
<span class="n">emb_szs</span> <span class="o">=</span> <span class="n">get_emb_sz</span><span class="p">(</span><span class="n">dls</span><span class="o">.</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span> <span class="c1"># `k` - embedding_size ( 40 ) mentioned in the paper for this dataset.</span>

<span class="c1"># prepare model architecture</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">FGCNN</span><span class="p">(</span><span class="n">emb_szs</span><span class="o">=</span><span class="n">emb_szs</span><span class="p">,</span> 
             <span class="n">conv_kernels</span><span class="o">=</span><span class="p">[</span><span class="mi">14</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span> 
             <span class="n">kernels</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
             <span class="n">dense_layers</span><span class="o">=</span><span class="p">[</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">2048</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">],</span>
             <span class="n">h</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
             <span class="n">hp</span><span class="o">=</span><span class="mi">2</span>
            <span class="p">)</span>

<span class="c1"># create tabular learner</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">TabularLearner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">BCELossFlat</span><span class="p">(),</span> <span class="n">opt_func</span><span class="o">=</span><span class="n">ranger</span><span class="p">)</span>

<span class="c1"># train and validate</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">BCELossFlat</span><span class="p">(),</span> <span class="n">n_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

